\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Reinforcement learning method and regression model }{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Q-learning }{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Neural Network as regression model}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Regression forest as regression model}{1}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}First attemp approach}{1}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}States construction:}{1}{subsection.1.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}Avaliable cells array (ACA)}{1}{subsubsection.1.5.1}}
\newlabel{section:ACA}{{1.5.1}{1}{Avaliable cells array (ACA)}{subsubsection.1.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Avalible moves, abbreviation and related boolean array.\relax }}{1}{table.1}}
\newlabel{table:S1}{{1}{1}{Avalible moves, abbreviation and related boolean array.\relax }{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}States construction: Dysfunctional version}{1}{subsection.1.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Definition of the regions in the maze.\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Regions}{{1}{2}{Definition of the regions in the maze.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1}Region definition}{2}{subsubsection.1.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.2}Normalized potential rewards}{2}{subsubsection.1.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces How looks like the second array. Where the $\omega _{R_{*}}$ is the weight related to the NPR in each region.\relax }}{2}{table.2}}
\newlabel{table:S2}{{2}{2}{How looks like the second array. Where the $\omega _{R_{*}}$ is the weight related to the NPR in each region.\relax }{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.3}Normalized potential danger}{2}{subsubsection.1.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces How looks like the second array. Where the $\omega _{R_{D_*}}$ is the weight related to the \textbf  {NPD} in each region.\relax }}{2}{table.3}}
\newlabel{table:S3}{{3}{2}{How looks like the second array. Where the $\omega _{R_{D_*}}$ is the weight related to the \textbf {NPD} in each region.\relax }{table.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.4}Drop a bomb (DB): Feasibility and usefulness}{2}{subsubsection.1.6.4}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces How looks like the third array. Where the $\omega _{R_{D_Cr}}$ is the weight that measure the usefulness to get coins by blowing up crates, and $\omega _{R_{D_O}}$ the feasible of killing an opponent\relax }}{2}{table.4}}
\newlabel{table:S4}{{4}{2}{How looks like the third array. Where the $\omega _{R_{D_Cr}}$ is the weight that measure the usefulness to get coins by blowing up crates, and $\omega _{R_{D_O}}$ the feasible of killing an opponent\relax }{table.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.5}Summary of state components}{2}{subsubsection.1.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Second attempt: Simplifying the state}{2}{subsection.1.7}}
\newlabel{section:SimNRP}{{1.7}{2}{Second attempt: Simplifying the state}{subsection.1.7}{}}
\citation{PageStrategySelection}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces State summarized: Unsuccessfully attempt\relax }}{3}{table.caption.3}}
\newlabel{table:S}{{5}{3}{State summarized: Unsuccessfully attempt\relax }{table.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of state formation, of ACA and NPR simplified: In the left side the avalible moves is showed, then ACA is: (1100), and in the right side, the direction of probable reward (DPR), and is given by: (0101). from operate with the $\land $ operator, we get the $NPR = (1100)\land (0101)=(0100)$ \relax }}{3}{figure.caption.4}}
\newlabel{fig:NPREx}{{2}{3}{Example of state formation, of ACA and NPR simplified: In the left side the avalible moves is showed, then ACA is: (1100), and in the right side, the direction of probable reward (DPR), and is given by: (0101). from operate with the $\land $ operator, we get the $NPR = (1100)\land (0101)=(0100)$ \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Rewards}{3}{subsection.1.8}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Training process}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Action selection strategy for exploration}{3}{subsection.2.1}}
\citation{paperDQL}
\@writefile{brf}{\backcite{PageStrategySelection}{{4}{2.1}{subsection.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Hyperparameters for Deep Q-Learning}{4}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Results}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Task 1:}{4}{subsection.3.1}}
\newlabel{section:Task1}{{3.1}{4}{Task 1:}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Total reward accumulated in episodes\relax }}{4}{figure.caption.6}}
\newlabel{fig:TRewAccu}{{3}{4}{Total reward accumulated in episodes\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Total reward in episodes. Plot inside: detailed behavior (in order to show the total reward tendence))\relax }}{4}{figure.caption.7}}
\newlabel{fig:TRewAll}{{4}{4}{Total reward in episodes. Plot inside: detailed behavior (in order to show the total reward tendence))\relax }{figure.caption.7}{}}
\@writefile{brf}{\backcite{paperDQL}{{4}{3.1}{table.caption.5}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Task 2:}{4}{subsection.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces State summarized\relax }}{5}{table.caption.5}}
\newlabel{table:Attemp2}{{6}{5}{State summarized\relax }{table.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Meassuring the learning to avoid invalid actions. Plot inside: detailed behavior (in order to show the xtendence))\relax }}{5}{figure.caption.8}}
\newlabel{fig:M1Coins}{{5}{5}{Meassuring the learning to avoid invalid actions. Plot inside: detailed behavior (in order to show the xtendence))\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Improving the agent and feedback}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Improving the agent}{5}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Meassuring the learning find the optimal path to get the coins. Plot inside: detailed behavior (in order to show the tendence))\relax }}{5}{figure.caption.9}}
\newlabel{fig:M1Coins}{{6}{5}{Meassuring the learning find the optimal path to get the coins. Plot inside: detailed behavior (in order to show the tendence))\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feedback}{5}{subsection.4.2}}
\citation{paperDQL}
\bibstyle{unsrtdin}
\bibdata{literatur}
\bibcite{pageStrategySelection}{1}
\bibcite{paperDQL}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Meassuring the learning to avoid invalid actions. Plot inside: detailed behavior (in order to show the tendence))\relax }}{6}{figure.caption.10}}
\newlabel{fig:M1Coins}{{7}{6}{Meassuring the learning to avoid invalid actions. Plot inside: detailed behavior (in order to show the tendence))\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Q-learning with regression forest prediction}{6}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Neural Networks}{6}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}General definitions:}{6}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Epsilon decay}{6}{subsubsection.4.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Motivation and overview}{6}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Model}{6}{section.6}}
\@writefile{brf}{\backcite{paperDQL}{{6}{6}{section.6}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Algorithm Deep Q Learning}{6}{subsection.6.1}}
